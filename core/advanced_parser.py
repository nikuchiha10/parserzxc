import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Optional
import logging
import time
from .parser_engine import ParserEngine, Article
from .article_manager import ArticleManager
from config import config

class AdvancedKnowledgeParser:
    def __init__(self):
        self.parser_engine = ParserEngine(config)
        self.article_manager = ArticleManager(config.DATA_DIR)
        self.logger = logging.getLogger(__name__)
        self.executor = ThreadPoolExecutor(max_workers=config.MAX_CONCURRENT_REQUESTS)
        
    def parse_articles_batch(self, articles_list: List[str], max_articles: int = None) -> Dict:
        """–ü–∞–∫–µ—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –ª–æ–≥–∏–∫–æ–π"""
        self.logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ {len(articles_list)} —Å—Ç–∞—Ç–µ–π")
        
        start_time = time.time()
        results = {
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'total_time': 0,
            'articles': []
        }
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
            self.parser_engine.init_selenium()
            
            # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
            if not self.parser_engine.smart_login():
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è")
                return results
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            articles_to_parse = articles_list
            if max_articles:
                articles_to_parse = articles_list[:max_articles]
            
            self.logger.info(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(articles_to_parse)} —Å—Ç–∞—Ç–µ–π")
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç–∞—Ç—å–∏
            for i, article_title in enumerate(articles_to_parse):
                self.logger.info(f"\n--- [{i+1}/{len(articles_to_parse)}] {article_title} ---")
                
                try:
                    # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏
                    search_results = self.parser_engine.search_articles(article_title)
                    
                    if not search_results:
                        self.logger.warning(f"‚ö†Ô∏è –°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {article_title}")
                        results['failed'] += 1
                        continue
                    
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    article_result = search_results[0]
                    
                    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å—Ç–∞—Ç—å–∏
                    article = self.parser_engine.parse_article_page(article_result['url'])
                    
                    if article:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å—é
                        saved_path = self.article_manager.save_article(article)
                        
                        if saved_path:
                            results['success'] += 1
                            results['articles'].append({
                                'title': article.title,
                                'url': article.url,
                                'word_count': article.word_count,
                                'file_path': saved_path
                            })
                        else:
                            results['failed'] += 1
                    else:
                        results['failed'] += 1
                    
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    time.sleep(config.REQUEST_DELAY)
                    
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏ '{article_title}': {e}")
                    results['failed'] += 1
                    continue
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.export_results()
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        finally:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
            self.parser_engine.close()
            
            # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è
            results['total_time'] = time.time() - start_time
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.log_results(results)
        
        return results
    
    async def async_parse_articles(self, articles_list: List[str]) -> Dict:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π)"""
        self.logger.info("‚ö° –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        
        # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –º–æ–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
        return self.parse_articles_batch(articles_list)
    
    def smart_search(self, query: str, use_semantic: bool = False) -> List[Dict]:
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏"""
        self.logger.info(f"üîç –£–º–Ω—ã–π –ø–æ–∏—Å–∫: {query}")
        
        try:
            self.parser_engine.init_selenium()
            
            if not self.parser_engine.smart_login():
                return []
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫
            results = self.parser_engine.search_articles(query)
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º
            if not results and use_semantic:
                results = self.expanded_search(query)
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ü–æ–∏—Å–∫ –ø–æ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º
            if not results:
                results = self.related_topics_search(query)
            
            self.parser_engine.close()
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def expanded_search(self, query: str) -> List[Dict]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
        # –ë–∞–∑–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        synonyms = {
            '—ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏—è': ['—ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ', '—ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ', '—ç–Ω–µ—Ä–≥–∏—è'],
            '–¥–æ–ª–≥': ['–∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å', '–∑–∞–¥–æ–ª–∂', '–Ω–µ–æ–ø–ª–∞—Ç–∞'],
            '—Ç–∞—Ä–∏—Ñ': ['—Ä–∞—Å—Ü–µ–Ω–∫–∞', '—Å—Ç–∞–≤–∫–∞', '—Ü–µ–Ω–∞'],
            '—Å—á–µ—Ç—á–∏–∫': ['–ø—Ä–∏–±–æ—Ä —É—á–µ—Ç–∞', '–ü–£', '–∏–∑–º–µ—Ä–∏—Ç–µ–ª—å'],
            '–ª—å–≥–æ—Ç–∞': ['–ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Ü–∏—è', '—Å–∫–∏–¥–∫–∞', '—Å—É–±—Å–∏–¥–∏—è']
        }
        
        search_queries = [query]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
        for word in query.split():
            if word.lower() in synonyms:
                for synonym in synonyms[word.lower()]:
                    new_query = query.replace(word, synonym)
                    search_queries.append(new_query)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º
        all_results = []
        for search_query in search_queries[:3]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
            results = self.parser_engine.search_articles(search_query)
            all_results.extend(results)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_results = []
        seen_urls = set()
        
        for result in all_results:
            if result['url'] not in seen_urls:
                unique_results.append(result)
                seen_urls.add(result['url'])
        
        return unique_results
    
    def related_topics_search(self, query: str) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º"""
        related_keywords = self.generate_related_keywords(query)
        all_results = []
        
        for keyword in related_keywords[:2]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            results = self.parser_engine.search_articles(keyword)
            all_results.extend(results)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_results = []
        seen_urls = set()
        
        for result in all_results:
            if result['url'] not in seen_urls:
                unique_results.append(result)
                seen_urls.add(result['url'])
        
        return unique_results
    
    def generate_related_keywords(self, query: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ–º
        # –ú–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ ML –º–æ–¥–µ–ª—å –∏–ª–∏ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é –ª–æ–≥–∏–∫—É
        topic_map = {
            '—ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏—è': ['–æ–ø–ª–∞—Ç–∞ —ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏–∏', '—Ç–∞—Ä–∏—Ñ—ã –Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ', '–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏'],
            '–¥–æ–ª–≥': ['–ø–æ–≥–∞—à–µ–Ω–∏–µ –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏', '—Ä–∞—Å—Å—Ä–æ—á–∫–∞ –ø–ª–∞—Ç–µ–∂–∞', '–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –∑–∞ –¥–æ–ª–≥–∏'],
            '—Ç–∞—Ä–∏—Ñ': ['–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∞—Ä–∏—Ñ–∞', '–º–Ω–æ–≥–æ—Ç–∞—Ä–∏—Ñ–Ω—ã–π —É—á–µ—Ç', '—Ç–∞—Ä–∏—Ñ–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ'],
            '—Å—á–µ—Ç—á–∏–∫': ['–∑–∞–º–µ–Ω–∞ —Å—á–µ—Ç—á–∏–∫–∞', '–ø–æ–∫–∞–∑–∞–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞', '–ø–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–±–æ—Ä–∞ —É—á–µ—Ç–∞'],
            '–ª—å–≥–æ—Ç–∞': ['–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ª—å–≥–æ—Ç—ã', '–ª—å–≥–æ—Ç—ã –≤–µ—Ç–µ—Ä–∞–Ω–∞–º', '—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –ª—å–≥–æ—Ç—ã']
        }
        
        related = []
        for word in query.split():
            if word.lower() in topic_map:
                related.extend(topic_map[word.lower()])
        
        return related if related else [query]
    
    def export_results(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        self.logger.info("üì§ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
        csv_path = self.article_manager.export_to_csv()
        if csv_path:
            self.logger.info(f"‚úÖ CSV —ç–∫—Å–ø–æ—Ä—Ç: {csv_path}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel
        excel_path = self.article_manager.export_to_excel()
        if excel_path:
            self.logger.info(f"‚úÖ Excel —ç–∫—Å–ø–æ—Ä—Ç: {excel_path}")
    
    def log_results(self, results: Dict):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        self.logger.info("\n" + "="*50)
        self.logger.info("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–†–°–ò–ù–ì–ê")
        self.logger.info("="*50)
        self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {results['success']}")
        self.logger.info(f"‚ùå –û—à–∏–±–∫–∏: {results['failed']}")
        self.logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {results.get('skipped', 0)}")
        self.logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {results['total_time']:.2f} —Å–µ–∫")
        self.logger.info(f"üìà –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {(results['success'] / (results['success'] + results['failed']) * 100):.1f}%")
        self.logger.info("="*50)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
        try:
            results_file = f"{config.LOGS_DIR}/parsing_results.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            self.logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def get_detailed_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        basic_stats = self.article_manager.get_stats()
        parsing_stats = self.get_parsing_stats()
        
        return {
            **basic_stats,
            **parsing_stats,
            'parser_version': '2.0.0',
            'last_run': time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def get_parsing_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        return {
            'articles_found': self.parser_engine.articles_found,
            'articles_parsed': self.parser_engine.articles_parsed,
            'success_rate': (self.parser_engine.articles_parsed / self.parser_engine.articles_found * 100) 
                            if self.parser_engine.articles_found > 0 else 0
        }
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.parser_engine.close()
        self.executor.shutdown()
